{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKBmr6UHkeMYRaiYmeud/u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smrutipunto/DS-for-argri/blob/main/DS_for_Agriculture_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGkS43oxlvg_"
      },
      "outputs": [],
      "source": [
        "#PRACTICAL 1 Web Scraping for Agricultural Data: Scrape weather data, soil data, and crop yield data from relevant websites - Tools: Python, BeautifulSoup, Scrapy.\n",
        "#Cleaning and Preprocessing Data: Handle missing values, outliers, and normalize data for further analysis. Exploratory Analysis of Crop Yield Data: Perform descriptive statistics and visualize data distributions, trends, and correlations\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "d=\"https://en.wikipedia.org/wiki/Crop\"\n",
        "r=requests.get(d)\n",
        "s=BeautifulSoup(r.text,'html')\n",
        "print(s)\n",
        "t=s.find('table',class_='nowraplinks hlist mw-collapsible autocollapse navbox-inner')\n",
        "print(t)\n",
        "crop_cols=s.find_all('th')\n",
        "crop_cols\n",
        "crop_table_cols=[t.text.strip() for t in crop_cols]\n",
        "print(crop_table_cols)\n",
        "import pandas as pd\n",
        "df=pd.DataFrame(columns=crop_table_cols)\n",
        "df\n",
        "column_data=s.find_all('tr')\n",
        "column_data\n",
        "for row in column_data:\n",
        "    row_data=row.find_all('td')\n",
        "    individual_row_data=[data.text.strip for data in row_data]\n",
        "    print(individual_row_data)\n",
        "    for row in column_data[1:]:\n",
        "    row_data=row.find_all('td')\n",
        "\n",
        "    #print(row_data)\n",
        "    individual_row_data=[data.text for data in row_data]\n",
        "    length=len(df)\n",
        "    df.loc[length]=individual_row_data\n",
        "#individual_row_data\n",
        "    #length=len(df)\n",
        "    #df.loc[length]=individual_row_data\n",
        "    df\n",
        "    df.to_csv(r'C:\\Shubhangi\\2024 25\\UDCS\\practicals\\pract 1\\agri.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Practical 2: Weather Prediction Using Time Series Analysis: Predict future weather patterns using historical weather data\n",
        "#practical 2\n",
        "> install.packages(\"forecast\")\n",
        "> library(forecast)\n",
        "> data1 <- read.csv(file.choose(),header=T)\n",
        "> data1\n",
        "> data1 <- read.csv(file.choose(),header=T)\n",
        "> data1\n",
        "> fit<-auto.arima(data1)\n",
        "> summary(fit)\n",
        "> forecasted_values <- forecast(fit, h = 12)\n",
        "> print(forecasted_values)\n",
        " Point Forecast Lo 80 Hi 80 Lo 95 Hi 95\n",
        " > plot(forecasted_values, main = \"ARIMA for rainfall prediction\")\n",
        ""
      ],
      "metadata": {
        "id": "cpxk4iBZAg54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crop Yield Prediction Using Machine Learning: Build a machine learning model to predict crop yields based on various factors (soil type, weather, etc.). Tools: Scikit-learn, XGBoost\n",
        "#practical 3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "df_yield = pd.read_csv('../input/crop-yield-prediction\u0002dataset/yield.csv')\n",
        "df_yield.shape\n",
        "(56717, 12)\n",
        "df_yield.head()\n",
        "# rename columns.\n",
        "df_yield = df_yield.rename(index=str, columns={\"Value\":\n",
        "\"hg/ha_yield\"})\n",
        "# drop unwanted columns.\n",
        "df_yield = df_yield.drop(['Year Code','Element Code','Element','Year\n",
        "Code','Area Code','Domain Code','Domain','Unit','Item Code'],\n",
        "axis=1)\n",
        "df_yield.head()\n",
        "df_yield.describe()\n",
        "df_yield.info()\n",
        "Index: 56717 entries, 0 to 56716\n",
        "Data columns (total 4 columns):\n",
        "f_rain = pd.read_csv('../input/crop-yield-prediction\u0002dataset/rainfall.csv')\n",
        "df_rain.head()\n",
        "df_rain['average_rain_fall_mm_per_year'] =\n",
        "pd.to_numeric(df_rain['average_rain_fall_mm_per_year'],errors =\n",
        "'coerce')\n",
        "df_rain.info()\n",
        "df_rain = df_rain.dropna()\n",
        "yield_df = pd.merge(df_yield, df_rain, on=['Year','Area'])\n",
        "yield_df.head()\n",
        "yield_df.describe()\n",
        "df_pes = pd.read_csv('../input/crop-yield-prediction\u0002dataset/pesticides.csv')\n",
        "13\n",
        "df_pes = df_pes.rename(index=str, columns={\"Value\":\n",
        "\"pesticides_tonnes\"})\n",
        "df_pes = df_pes.drop(['Element','Domain','Unit','Item'], axis=1)\n",
        "df_pes.head()\n",
        "yield_df = pd.merge(yield_df, df_pes, on=['Year','Area'])\n",
        "yield_df.shape\n",
        "AVERAGE Temperature\n",
        "avg_temp= pd.read_csv('../input/crop-yield-prediction\u0002dataset/temp.csv')\n",
        "avg_temp = avg_temp.rename(index=str, columns={\"year\": \"Year\",\n",
        "\"country\":'Area'})\n",
        "avg_temp.head()\n",
        "yield_df = pd.merge(yield_df,avg_temp, on=['Area','Year'])\n",
        "yield_df.head()\n",
        "yield_df.describe()\n",
        "yield_df.groupby('Item').count()\n",
        "yield_df.describe()\n",
        "yield_df.groupby(['Area'],sort=True)['hg/ha_yield'].sum().nlargest(1\n",
        "0)\n",
        "yield_df.groupby(['Item','Area'],sort=True)['hg/ha_yield'].sum().nla\n",
        "rgest(10)\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "correlation_data=yield_df.select_dtypes(include=[np.number]).corr()\n",
        "mask = np.zeros_like(correlation_data, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.palette=\"vlag\"\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(correlation_data, mask=mask, cmap=cmap, vmax=.3,\n",
        "center=0,\n",
        " square=True, linewidths=.5, cbar_kws={\"shrink\": .5});\n",
        " #DATA PREPROCESSING\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "yield_df_onehot = pd.get_dummies(yield_df, columns=['Area',\"Item\"],\n",
        "prefix = ['Country',\"Item\"])\n",
        "features=yield_df_onehot.loc[:, yield_df_onehot.columns !=\n",
        "'hg/ha_yield']\n",
        "label=yield_df['hg/ha_yield']\n",
        "features = features.drop(['Year'], axis=1)\n",
        "#SCALING FEATURES\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()\n",
        "features=scaler.fit_transform(features)\n",
        "#TRAINING DATA\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_labels, test_labels =\n",
        "train_test_split(features, label, test_size=0.2, random_state=42)\n",
        "#TESTING DATA\n",
        "#setting test data to columns from dataframe and excluding\n",
        "'hg/ha_yield' values where ML model should be predicting\n",
        "test_df=pd.DataFrame(test_data,columns=yield_df_onehot.loc[:,\n",
        "yield_df_onehot.columns != 'hg/ha_yield'].columns)\n",
        "# using stack function to return a reshaped DataFrame by pivoting\n",
        "the columns of the current dataframe\n",
        "cntry=test_df[[col for col in test_df.columns if 'Country' in\n",
        "col]].stack()[test_df[[col for col in test_df.columns if 'Country'\n",
        "in col]].stack()>0]\n",
        "cntrylist=list(pd.DataFrame(cntry).index.get_level_values(1))\n",
        "countries=[i.split(\"_\")[1] for i in cntrylist]\n",
        "itm=test_df[[col for col in test_df.columns if 'Item' in\n",
        "col]].stack()[test_df[[col for col in test_df.columns if 'Item' in\n",
        "col]].stack()>0]\n",
        "itmlist=list(pd.DataFrame(itm).index.get_level_values(1))\n",
        "items=[i.split(\"_\")[1] for i in itmlist]\n",
        "test_df.drop([col for col in test_df.columns if 'Item' in\n",
        "col],axis=1,inplace=True)\n",
        "test_df.drop([col for col in test_df.columns if 'Country' in\n",
        "col],axis=1,inplace=True)\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "szk0AX7XBtip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}